2023-02-06 13:40:48,135 - mmcls - INFO - Environment info:
------------------------------------------------------------
sys.platform: win32
Python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
CUDA available: False
MSVC: 用于 x64 的 Microsoft (R) C/C++ 优化编译器 19.34.31937 版
GCC: n/a
PyTorch: 1.13.1
PyTorch compiling details: PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=0, USE_CUDNN=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.14.1
OpenCV: 4.7.0
MMCV: 1.7.1
MMCV Compiler: MSVC 192829924
MMCV CUDA Compiler: not available
MMClassification: 0.25.0+
------------------------------------------------------------

2023-02-06 13:40:48,135 - mmcls - INFO - Distributed training: False
2023-02-06 13:40:48,229 - mmcls - INFO - Config:
model = dict(
    type='ImageClassifier',
    backbone=dict(type='MobileNetV2', widen_factor=1.0),
    neck=dict(type='GlobalAveragePooling'),
    head=dict(
        type='LinearClsHead',
        num_classes=5,
        in_channels=1280,
        loss=dict(type='CrossEntropyLoss', loss_weight=1.0),
        topk=(1, 5)))
load_from = 'mobilenet_v2_batch256_imagenet_20200708-3b2dc3af.pth'
data = dict(
    samples_per_gpu=32,
    workers_per_gpu=2,
    train=dict(
        type='CustomDataset',
        data_prefix='data\train',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='RandomResizedCrop', size=224, backend='pillow'),
            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='ToTensor', keys=['gt_label']),
            dict(type='Collect', keys=['img', 'gt_label'])
        ]),
    val=dict(
        type='CustomDataset',
        data_prefix='data\val',
        ann_file='data\val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', size=(256, -1), backend='pillow'),
            dict(type='CenterCrop', crop_size=224),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ]),
    test=dict(
        type='CustomDataset',
        data_prefix='data\val',
        ann_file='data\val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', size=(256, -1), backend='pillow'),
            dict(type='CenterCrop', crop_size=224),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ]))
evaluation = dict(interval=1, metric='accuracy')
optimizer = dict(type='SGD', lr=0.005, momentum=0.9, weight_decay=4e-05)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', gamma=0.98, step=1)
runner = dict(type='EpochBasedRunner', max_epochs=5)
checkpoint_config = dict(interval=5)
log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
resume_from = None
workflow = [('train', 1)]
work_dir = 'work-dir'
gpu_ids = [0]

2023-02-06 13:40:48,230 - mmcls - INFO - Set random seed to 1504059428, deterministic: False
2023-02-06 13:40:48,611 - mmcls - INFO - load checkpoint from local path: mobilenet_v2_batch256_imagenet_20200708-3b2dc3af.pth
2023-02-06 13:40:48,673 - mmcls - WARNING - The model and loaded state dict do not match exactly

size mismatch for head.fc.weight: copying a param with shape torch.Size([1000, 1280]) from checkpoint, the shape in current model is torch.Size([5, 1280]).
size mismatch for head.fc.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([5]).
2023-02-06 13:40:48,675 - mmcls - INFO - Start running, host: ming11.ni@swxdhc103057, work_dir: E:\Study\OpenMMLab\CodeWork1\work-dir
2023-02-06 13:40:48,675 - mmcls - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-02-06 13:40:48,675 - mmcls - INFO - workflow: [('train', 1)], max: 5 epochs
2023-02-06 13:40:48,675 - mmcls - INFO - Checkpoints will be saved to E:\Study\OpenMMLab\CodeWork1\work-dir by HardDiskBackend.
2023-02-06 13:41:51,076 - mmcls - INFO - Epoch [1][10/72]	lr: 5.000e-03, eta: 0:36:23, time: 6.239, data_time: 1.091, loss: 1.2546
2023-02-06 13:42:38,045 - mmcls - INFO - Epoch [1][20/72]	lr: 5.000e-03, eta: 0:30:59, time: 4.698, data_time: 0.007, loss: 0.4484
2023-02-06 13:43:25,131 - mmcls - INFO - Epoch [1][30/72]	lr: 5.000e-03, eta: 0:28:40, time: 4.709, data_time: 0.004, loss: 0.3749
2023-02-06 13:44:12,097 - mmcls - INFO - Epoch [1][40/72]	lr: 5.000e-03, eta: 0:27:07, time: 4.697, data_time: 0.004, loss: 0.4132
2023-02-06 13:44:56,737 - mmcls - INFO - Epoch [1][50/72]	lr: 5.000e-03, eta: 0:25:37, time: 4.464, data_time: 0.004, loss: 0.4845
2023-02-06 13:45:45,303 - mmcls - INFO - Epoch [1][60/72]	lr: 5.000e-03, eta: 0:24:43, time: 4.856, data_time: 0.004, loss: 0.5531
2023-02-06 13:46:34,963 - mmcls - INFO - Epoch [1][70/72]	lr: 5.000e-03, eta: 0:23:54, time: 4.966, data_time: 0.008, loss: 0.5138
2023-02-06 13:47:21,044 - mmcls - INFO - Epoch(val) [1][18]	accuracy_top-1: 83.3916, accuracy_top-5: 100.0000
2023-02-06 13:48:27,550 - mmcls - INFO - Epoch [2][10/72]	lr: 4.900e-03, eta: 0:23:19, time: 6.647, data_time: 0.229, loss: 0.5815
2023-02-06 13:49:17,078 - mmcls - INFO - Epoch [2][20/72]	lr: 4.900e-03, eta: 0:22:26, time: 4.956, data_time: 0.010, loss: 0.6007
2023-02-06 13:50:03,164 - mmcls - INFO - Epoch [2][30/72]	lr: 4.900e-03, eta: 0:21:25, time: 4.609, data_time: 0.005, loss: 0.6172
2023-02-06 13:50:49,291 - mmcls - INFO - Epoch [2][40/72]	lr: 4.900e-03, eta: 0:20:27, time: 4.613, data_time: 0.006, loss: 0.5560
2023-02-06 13:51:36,093 - mmcls - INFO - Epoch [2][50/72]	lr: 4.900e-03, eta: 0:19:33, time: 4.680, data_time: 0.005, loss: 0.4213
2023-02-06 13:52:22,751 - mmcls - INFO - Epoch [2][60/72]	lr: 4.900e-03, eta: 0:18:39, time: 4.666, data_time: 0.007, loss: 0.3917
2023-02-06 13:53:10,423 - mmcls - INFO - Epoch [2][70/72]	lr: 4.900e-03, eta: 0:17:47, time: 4.767, data_time: 0.006, loss: 0.3868
2023-02-06 13:53:42,069 - mmcls - INFO - Epoch(val) [2][18]	accuracy_top-1: 91.9580, accuracy_top-5: 100.0000
2023-02-06 13:54:28,121 - mmcls - INFO - Epoch [3][10/72]	lr: 4.802e-03, eta: 0:16:32, time: 4.605, data_time: 0.221, loss: 0.5411
2023-02-06 13:55:13,857 - mmcls - INFO - Epoch [3][20/72]	lr: 4.802e-03, eta: 0:15:41, time: 4.574, data_time: 0.007, loss: 0.3540
2023-02-06 13:55:58,011 - mmcls - INFO - Epoch [3][30/72]	lr: 4.802e-03, eta: 0:14:48, time: 4.415, data_time: 0.005, loss: 0.4121
2023-02-06 13:56:44,659 - mmcls - INFO - Epoch [3][40/72]	lr: 4.802e-03, eta: 0:14:00, time: 4.665, data_time: 0.004, loss: 0.3092
2023-02-06 13:57:30,364 - mmcls - INFO - Epoch [3][50/72]	lr: 4.802e-03, eta: 0:13:10, time: 4.570, data_time: 0.006, loss: 0.3516
2023-02-06 13:58:15,356 - mmcls - INFO - Epoch [3][60/72]	lr: 4.802e-03, eta: 0:12:20, time: 4.499, data_time: 0.004, loss: 0.3591
2023-02-06 13:59:06,675 - mmcls - INFO - Epoch [3][70/72]	lr: 4.802e-03, eta: 0:11:36, time: 5.132, data_time: 0.005, loss: 0.3488
2023-02-06 13:59:39,171 - mmcls - INFO - Epoch(val) [3][18]	accuracy_top-1: 93.0070, accuracy_top-5: 100.0000
2023-02-06 14:00:32,510 - mmcls - INFO - Epoch [4][10/72]	lr: 4.706e-03, eta: 0:10:36, time: 5.333, data_time: 0.222, loss: 0.3799
2023-02-06 14:01:20,428 - mmcls - INFO - Epoch [4][20/72]	lr: 4.706e-03, eta: 0:09:49, time: 4.792, data_time: 0.005, loss: 0.3210
2023-02-06 14:02:04,788 - mmcls - INFO - Epoch [4][30/72]	lr: 4.706e-03, eta: 0:09:00, time: 4.436, data_time: 0.005, loss: 0.2834
2023-02-06 14:02:49,975 - mmcls - INFO - Epoch [4][40/72]	lr: 4.706e-03, eta: 0:08:11, time: 4.519, data_time: 0.007, loss: 0.2213
2023-02-06 14:03:33,632 - mmcls - INFO - Epoch [4][50/72]	lr: 4.706e-03, eta: 0:07:23, time: 4.366, data_time: 0.005, loss: 0.2346
2023-02-06 14:04:22,486 - mmcls - INFO - Epoch [4][60/72]	lr: 4.706e-03, eta: 0:06:36, time: 4.885, data_time: 0.005, loss: 0.2843
2023-02-06 14:05:18,979 - mmcls - INFO - Epoch [4][70/72]	lr: 4.706e-03, eta: 0:05:51, time: 5.647, data_time: 0.006, loss: 0.2978
2023-02-06 14:05:52,696 - mmcls - INFO - Epoch(val) [4][18]	accuracy_top-1: 92.8322, accuracy_top-5: 100.0000
2023-02-06 14:06:40,167 - mmcls - INFO - Epoch [5][10/72]	lr: 4.612e-03, eta: 0:04:52, time: 4.747, data_time: 0.224, loss: 0.2336
2023-02-06 14:07:28,841 - mmcls - INFO - Epoch [5][20/72]	lr: 4.612e-03, eta: 0:04:05, time: 4.867, data_time: 0.004, loss: 0.3012
2023-02-06 14:08:14,660 - mmcls - INFO - Epoch [5][30/72]	lr: 4.612e-03, eta: 0:03:18, time: 4.582, data_time: 0.006, loss: 0.1885
2023-02-06 14:09:02,794 - mmcls - INFO - Epoch [5][40/72]	lr: 4.612e-03, eta: 0:02:31, time: 4.814, data_time: 0.007, loss: 0.2467
2023-02-06 14:09:48,778 - mmcls - INFO - Epoch [5][50/72]	lr: 4.612e-03, eta: 0:01:43, time: 4.598, data_time: 0.004, loss: 0.1759
2023-02-06 14:10:34,374 - mmcls - INFO - Epoch [5][60/72]	lr: 4.612e-03, eta: 0:00:56, time: 4.560, data_time: 0.005, loss: 0.2536
2023-02-06 14:11:18,807 - mmcls - INFO - Epoch [5][70/72]	lr: 4.612e-03, eta: 0:00:09, time: 4.443, data_time: 0.004, loss: 0.2461
2023-02-06 14:11:24,193 - mmcls - INFO - Saving checkpoint at 5 epochs
2023-02-06 14:11:55,606 - mmcls - INFO - Epoch(val) [5][18]	accuracy_top-1: 93.8811, accuracy_top-5: 100.0000
